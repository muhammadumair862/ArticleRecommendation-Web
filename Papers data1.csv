paper_id,paper_title,author_keywords,abstract,area
1,Bayesian Nonparametric Inverse Reinforcement Learning for Switched Markov Decision Processes,"Markov Decision Processes, Bayesian Nonparametrics, Inverse Reinforcement Learning","In this paper we develop a Bayesian nonparametric Inverse Reinforcement Learning technique for switched Markov Decision Processes (MDP). Similar to switched linear dynamical systems, switched MDP (sMDP)can be used to represent complex behaviors composed of temporal transitions between simpler behaviors each represented by a standard MDP. We use sticky Hierarchical Dirichlet Process as a nonparametric prior on the sMDP model space, and describe a Markov Chain Monte Carlo method to efficiently learn the posterior on the sMDP models given the behavior data. We demonstrate the effectiveness of sMDP models for learning, prediction and  classification of complex agent behaviors in a simulated surveillance scenario.",Machine Learning I
2,State Abstraction in Reinforcement Learning by Eliminating Useless Dimensions,"Reinforcement learning, state abstraction, intelligent agent, complexity reduction","Q-learning and other linear dynamic learning algorithms are subject to Bellmans curse of dimensionality for any realistic learning problem. This paper introduces a framework for satisficing state abstraction one that reduces state dimensionality, improving convergence and reducing computational and memory resources by eliminating useless state dimensions. Statistical parameters that are dependent on the state and Q-values identify the relevance of a given state space to a task space and allow state elements that contribute least to task learning to be discarded. Empirical results of applying state abstraction to a canonical single-agent path planning task and to a more difficult multi-agent foraging problem demonstrate utility of the proposed methods in improving learning convergence and performance in resource-constrained learning problems.",Machine Learning I
3,A knowledge growth and consolidation framework for lifelong machine learning systems,"Lifelong machine learning, oblivion criterion, knowledge topology and acquisition, declarative learning","A more effective vision of machine learning systems entails tools that are able to improve task after task and to reuse the patterns and knowledge that are acquired previously for future tasks. This incremental, long-life view of machine learning goes beyond most of state-of-the-art machine learning techniques that learn throw-away models. In this paper we present a long-life knowledge acquisition, evaluation and consolidation framework that is designed to work with any rule-based machine learning or inductive inference engine and integrate it into a long-life learner. In order to do that we work over the graph of working memory rules and introduce several topological metrics over it from which we derive an oblivion criterion to drop useless rules from working memory and a consolidation process to promote the rules to the knowledge base. We evaluate the framework on a series of tasks in a chess rule learning domain.",Machine Learning I
4,LaCova: A Tree-Based Multi-Label Classifier using Label Covariance as Splitting Criterion,"Multi-label learning, Decision Trees, Covariance Matrix, Splitting Criteria","Dealing with multiple labels is a supervised learning problem of increasing importance. Multi-label classifiers face the challenge of exploiting correlations between labels. While in existing work these correlations are often modelled globally, in this paper we use the divide-and-conquer approach of decision trees which enables taking local decisions about how best to model label dependency. The resulting algorithm establishes a tree-based multi-label classifier called LaCova which dynamically interpolates between two well-known baseline methods: Binary Relevance, which assumes all labels independent, and Label Powerset, which learns the joint label distribution. The key idea is a splitting criterion based on the label covariance matrix at that node, which allows us to choose between a horizontal split (branching on a feature) and a vertical split (separating the labels). Empirical results on 12 data sets show strong performance of the proposed method, particularly on data sets with hundreds of labels.",Machine Learning I
5,Combining Exact And Metaheuristic Techniques For Learning Extended Finite-State Machines From Test Scenarios and Temporal Properties,"finite-state machines, constraint satisfaction problem, ant colony optimization, model checking, control, hybrid algorithms",This paper addresses the problem of learning extended finite-state machine (EFSM) from user-specified behavior examples (test scenarios) and temporal properties. We show how to combine exact EFSM inference algorithms~(that always find a solution if it exists) and metaheuristics to derive an efficient combined EFSM learning algorithm. We also present a new exact EFSM inference algorithm based on Constraint Satisfaction Problem (CSP) solvers. Experimental results are reported showing that the new combined algorithm significantly outperforms a previously used metaheuristic.,Machine Learning I
6,Human action recognition based on recognition of linear patterns in action bank features using convolutional neural networks,"Human action recognition, action bank features, deep convolutional network","In this paper, we proposed a deep convolutional network architecture for recognizing human actions in videos using action bank features. Action bank features computed against of a predefined set of videos known as an action bank, contain linear patterns representing the similarity of the video against the action bank videos. Due to the independence of the patterns across action bank features, a convolutional neural network with linear masks is considered to capture the local patterns associated with each action. The knowledge gained through training is used to assign an action label to videos during testing. Experiments conducted on UCF50 dataset demonstrates the effectiveness of the proposed approach in capturing and recognizing these linear local patterns.",Neural Networks I
7,A Cyclic Contrastive Divergence Learning Algorithm for High-order RBMs,"High-order RBMs, Cyclic Contrastive Divergence Learning, Gradient Approximation, Convergence, Upper Bound","The Restricted Boltzmann Machine (RBM), a special case of general Boltzmann Machines and a typical Probabilistic Graphical Models, has attracted much attention in recent years due to its powerful ability in extracting features and representing the distribution underlying the training data. A most commonly used algorithm in learning RBMs is called Contrastive Divergence (CD) proposed by Hinton, which starts a Markov chain at a data point and runs the chain for only a few iterations to get a low variance estimator. However, when referring to a high-order RBM, since there are interactions among its visible layers, the gradient approximation via CD learning usually becomes far from the log-likelihood gradient and even may cause CD learning to fall into the infinite loop with high reconstruction error. In this paper, a new algorithm named Cyclic Contrastive Divergence (CCD) is introduced for learning high-order RBMs. Unlike the standard CD algorithm, CCD updates the parameters according to each visible layer in turn, by borrowing the idea of Cyclic Block Coordinate Descent method. To evaluate the performance of the proposed CCD algorithm, regarding to high-order RBMs learning, both algorithms CCD and standard CD are theoretically analyzed, including convergence, estimate upper bound and both biases comparison, from which the superiority of CCD learning is revealed. Experiments of handwritten digit classification task on MNIST dataset are performed. The experimental results show that CCD is more applicable and consistently outperforms the standard CD in both convergent speed and performance.",Neural Networks I
8,Facial expression recognition using kinect depth sensor and convolutional neural networks,"convolutional neural networks (CNN), Facial expression recognition","Facial expression recognition is an active area of research with applications in the design of Human Computer Interaction (HCI) systems. In this paper, we propose an approach for facial expression recognition using deep convolutional neural networks (CNN) based on features generated from depth information only. The Gradient direction information of depth data is used to represent facial information, due its invariance to distance from the sensor. The ability of a convolutional neural networks (CNN) to learn local discriminative patterns from data is used to recognize facial expressions from the representation of unregistered facial images. Experiments conducted on EURECOM kinect face dataset demonstrate the effectiveness of the proposed approach.",Neural Networks I
9,Improving Performance on Problems with Few Labelled Data by Reusing Stacked Auto-Encoders,"transfer learning, deep learning, artificial neural networks","Deep architectures have been used in transfer learning applications, with the aim of improving the performance of networks designed for a given problem by reusing knowledge from another problem. In this work we addressed the transfer of knowledge between deep networks used as classifiers of digit and shape images, considering cases where only the set of class labels, or only the data distribution, changed from source to target problem. Our main goal was to study how the performance of knowledge transfer between such problems would be affected by varying the number of layers being retrained and the amount of data used in that retraining. Generally, reusing networks trained for a different label set led to better results than reusing networks trained for a different data distribution. In particular, reusing for less classes a network trained for more classes was beneficial for virtually any amount of training data. In all cases, retraining only one layer to save time consistently led to poorer performance. The results obtained when retraining for upright digits a network trained for rotated digits raise the hypothesis that transfer learning could be used to better deal with image classification problems in which only a small amount of labelled data is available for training.",Neural Networks I
10,An Analysis of Instance Selection for Neural Networks to Improve Training Speed,"instance selection, neural networks, training speed","Training Artificial Neural Networks (ANN) is relatively slow compared to many other machine learning algorithms.  In this study, we focus on instance selection to improve training speed.  We first evaluate the effectiveness of instance selection algorithms for k-nearest neighbor algorithms with ANN.  We then analyze factors in accuracy distance from decision boundary, dense regions, and class distributions, and propose new instance selection algorithms.  We discuss the tradeoff between accuracy and training speed, and introduce a measure for the tradeoff.  Our empirical results on real data sets indicate that our proposed RDI is more effective with ANN.",Neural Networks I
11,Human action recognition based on MOCAP information using convolution neural networks,"convolutional neural networks (CNN), motion capture (MOCAP)","Human action recognition is an important component in semantic analysis of human behavior. In this paper, we propose an approach for human action recognition based on motion capture (MOCAP) information using convolutional neural networks (CNN). Distance based metrics computed from MOCAP information of only three human joints are used in the computation of features. The range and temporal variation of these distance metrics are considered in the design of features which are discriminative for action recognition. A convolutional neural network capable of recognizing local patterns is used to identify human actions from the temporal variation of these features, which are distorted due to the inconsistency in the execution of actions across observations and subjects. Experiments conducted on Berkeley MHAD dataset demonstrate the effectiveness of the proposed approach.",Neural Network II
12,Improving Named Entity Recognition for Morphologically Rich Languages using Word Embeddings,"Czech NER, Named Entity Recognition, Word Embeddings, Skip-gram, Turkish NER","In this paper, we addressed the Named Entity Recognition (NER) problem for morphologically rich languages by employing a semi-supervised learning approach based on neural networks. We adopted a fast unsupervised method for learning continuous vector representations of words, and used these representations along with language independent features to develop a NER system. We evaluated our system for the highly inflectional Turkish and Czech languages and obtained better F-score performances than the previously published results for these languages. We improved the state-of-the-art F-score by 2.26% for Turkish and 1.53% for Czech. Unlike the previous state-of-the-art systems developed for these languages, our system does not make use of any language dependent features. Therefore, we believe it can easily be applied to other morphologically rich languages.",Neural Network II
13,Multi-Variable Neural Network Forecasting Using Two Stage Feature Selection,"forecasting, feature selection, neural networks","This paper proposes a novel neural network based forecaster that predicts more than one variable at a time. A two stage neural network training algorithm is used that employs Newtons algorithm to estimate a vector of hidden unit optimal learning factors in each iteration. In order to reduce the size of the neural network and train it more effectively, the forecaster uses both subsetting and transformation types of feature selection, reducing the number of neural net inputs by 70 %.",Neural Network II
14,Adaptive restructuring of radial basis functions using integrate-and-fire neurons,"machine learning, radial basis functions, neural networks, feed-forward networks","This paper proposes a neurobiology-based extension of integrate-and-fire models of Radial Basis Function Neural Networks (RBFNN) that adapts to novel stimuli by means of dynamic restructuring of the networks structural parameters. The new architecture automatically balances synapses modulation, re-centers hidden Radial Basis Functions (RBFs), and stochastically shifts parameter-space decision planes to maintain homeostasis. Example results are provided throughout the paper to illustrate the effects of changes to the RBFNN model.",Neural Network II
15,One-shot periodic activity recognition using Convolutional Neural Networks,"Human activity recognition, Convolutional Neural Networks (CNN)","Activities capture vital facts for the semantic analysis of human behavior. In this paper, we propose a method for recognizing human activities based on periodic actions from a single instance using convolutional neural networks (CNN). The height of the foot above the ground is considered as features to discriminate human locomotion activities. The periodic nature of actions in these activities is exploited to generate the training cases from a single instance using a sliding window. Also, the capability of a convolutional neural network to learn local visual patterns is exploited for human activity recognition. Experiments on Carnegie Mellon University (CMU) Mocap dataset demonstrate the effectiveness of the proposed approach.",Neural Network II
16,Semi-Supervised Kernel-Based Temporal Clustering,"Kernel k-means, Semi-supervised clustering, Temporal segmentation","In this paper, we adapt two existing methods to perform semi-supervised temporal clustering: Aligned Cluster Analysis (ACA), a temporal clustering algorithm, and Constrained Spectral Clustering, a semi-supervised clustering algorithm. In the first method, we add side information in the form of pairwise constraints to its objective function, and in the second, we add a temporal search to its framework. We also extend both methods by propagating the constraints throughout the whole similarity matrix. In order to validate the advantage of the proposed semi-supervised methods to temporal clustering, we evaluate them in comparison to their original versions as well as another semi-supervised temporal cluster on three temporal datasets. The results show that the proposed methods are competitive and provide good improvement over the unsupervised approaches.",Semi-Supervised Learning
17,Learning to Rank with Only Positive Examples,"Information Need Modeling, Positive Unlabeled Learning, Transductive Learning, Search by Multiple Examples","A key to successfully retrieve relevant documents lies in how users express their information needs using keywords as queries.  However, for many users, it is difficult for them to use keywords to express their information needs. Search-By-Multiple-Examples (SBME), a promising method for overcoming this problem, allows users to specify their information needs as a set of relevant documents rather than as a set of keywords. In this study, we propose a Transductive Positive Unlabeled learning (TPU learning) based framework for document ranking The framework consists of two steps: 1) identifying potential relevant documents to reduce the searching space from the entire data collection to a smaller dataset, and 2) adopting TPU learning methods to re-rank the searching space by treating the relevant documents from a user as positive examples P and the documents in the searching space as unlabeled data U. Using MAP and p@k, we evaluate two state-of-the-art PU learning algorithms and the Rocchio classifier (Rc) for document ranking in the proposed framework with different sizes of P to simulate users online search behaviors. We then adopt the idea of ensemble learning to combine Rc with the two state-of-the-art PU learning algorithms respectively. Experiments conducted on two real datasets show that the ensemble learning based methods lead to significant improvement in performance.",Semi-Supervised Learning
18,Geometric PDEs on weighted graphs for semi-supervised classification,"Equations, Databases, Standards, Labeling, Vectors, Image processing, Classification algorithms","In this paper, we consider the adaptation of two Partial Differential Equations (PDEs) on weighted graphs, p-Laplacian and eikonal equation, for semi-supervised classification tasks. These equations are a discrete analogue of well known geometric PDEs, which are widely used in image processing. While the p-Laplacian on graphs was intensively used in data classification, few works relate to the eikonal equation for data classification. The methods are illustrated through semi-supervised classification tasks on databases, where we compare the two algorithms. The results show that these methods perform well regarding the state-of-the-art and are applicable to the task of semi-supervised classification.",Semi-Supervised Learning
19,Post-Processing Association Rules using Networks and Transductive Learning,"Networks, Association Rules, Pruning, Post-Processing, Label Propagation","Association is widely used to find relations among items in a given database. However, finding the interesting patterns is a challenging task due to the large number of rules that are generated. Traditionally, this task is done by post-processing approaches that explore and direct the user to the interesting rules of the domain. Some of these approaches use the user's knowledge to guide the exploration according to what is defined (thought) as interesting by the user. However, this definition is done before the process starts. Therefore, the user must know what may be and what may not be interesting to him/her. This work proposes a general association rule post-processing approach that extracts the user's knowledge during the post-processing phase. That way, the user does not need to have a prior knowledge in the database. For that, the proposed approach models the association rules in a network, uses its measures to suggest rules to be classified by the user and, then, propagates these classifications to the entire network using transductive learning algorithms. Therefore, this approach treats the post-processing problem as a classification task. Experiments were carried out to demonstrate that the proposed approach reduces the number of rules to be explored by the user and directs him/her to the potentially interesting rules of the domain.",Semi-Supervised Learning
20,"Variational Inference on Infinite Mixtures of Inverse Gaussian, Multinomial Probit and Exponential Regression","Variational Inference, Probit Regression, Exponential Regression, Inverse Gaussian Regression, Dirichlet Process","We introduce a new class of methods and inference techniques for infinite mixtures of Inverse Gaussian, Multinomial Probit and Exponential Regression, models that belong to the widely applicable framework of Generalized Linear Model (GLM). We characterize the joint distribution of the response and covariates via a Stick-Breaking Prior. This leads to, in the various cases, nonparametric models for an infinite mixture of Inverse Gaussian, Multinomial Probit and Exponential Regression. Estimates of the localized mean function which maps the covariates to the response are presented. We prove the weak consistency for the posterior distribution of the Exponential model (SB-EX) and then propose mean field variational inference algorithms for the Inverse Gaussian, Multinomial Probit and Exponential Regression. Finally, we demonstrate their superior accuracy in comparison to several other regression models such as, Gaussian Process Regression, Dirichlet Process Regression, etc.",Semi-Supervised Learning
21,Varying Coefficient Models for Analyzing the Effects of Risk Factors on Pregnant Women's Blood Pressure,"Varying Coefficient Model, longitudinal data, gestational hypertension","In the study of gestational hypertension, most of studies focused on whether a risk factor is associated with gestational hypertension. However, according to the clinical experience, it is important to know the effects of risk factors on women's blood pressure during pregnancy. Thus, we examined the effects of known risk factors (age, hematocrit, etc.) over gestational age. We also examined whether the effects of known risk factors are different between gestational hypertension group and preeclampsia group. These were studied in 412 pregnant women including 1874 clinical follow-up records. On the longitudinal clinical data of pregnant women, varying coefficient models were applied to study the effects of known risk factors over gestational age. The results showed that the effects of known risk factors varied with gestational age, and the changing processes of known risk factors over gestational age were different between gestational hypertension group and preeclampsia group. In final, we used the relative error as the criterion to assess the accuracy of the estimated varying coefficient model. The relative errors for total clinical data, gestational hypertension group and preeclampsia group were 13.3%, 8.1% and 14.3%, respectively.",Medicine and Bioinformatics
22,Learning Score Systems for Patient Mortality Prediction in Intensive Care Units via Orthogonal Matching Pursuit,"logistic regression, Intensive care units, mortality rate prediction, score systems, orthogonal matching pursuit","The problem of predicting outcome of patients in intensive care units (ICUs) is of great importance in critical care medicine, and has wide implications for quality control in ICUs. A dominant approach to this problem has been to use an ICU score system such as the Acute Physiology and Chronic Health Evaluation (APACHE) system and the Simplified Acute Physiology Score (SAPS) system, to compute a certain severity score for a patient from a set of clinical observations, and apply a logistic regression model on this score to obtain an estimate of the probability of mortality for the patient, owing to their simplicity, these methods are widely used by clinicians. However, existing ICU score systems, which are built from a fixed set of patient data, often perform poorly when applied to a patient population with different characteristics, also, with changes in patient characteristics, a score system built from a given patient data set becomes suboptimal over time. Moreover, most of these score systems are built using semi-automated procedures, making it difficult to adapt them to a new patient population. Thus there is a huge need for adaptive methods that can automatically learn predictive models from a given set of patient data. Indeed, there has been much work in recent years on applying various machine learning methods to this problem, however these methods learn different representations from the score systems preferred by clinicians. In this work, we develop a machine learning method based on orthogonal matching pursuit that automatically learns a score system type model, which enjoys the benefits of both worlds: like other machine learning methods, it is adaptive, like standard score systems, it uses a representation that is easy for clinicians to understand. Experiments on real-world patient data sets show that our method outperforms standard ICU score systems, and performs at least as well as other machine learning methods for this problem.",Medicine and Bioinformatics
23,Implementation of machine learning for classifying hemiplegic gait disparity through use of a force plate,"Force plate, hemiplegic gait, logistic regression, machine learning, gait analysis","The synergy of gait analysis tools with machine learning enables the capacity to classify disparity existing in hemiplegic gait. Hemiplegic gait is characterized by an affected and unaffected leg, which can be quantified by the measurement of a force plate. The characteristic features of the force plate recording for gait consist of a two local maxima that represent the braking and push off phase of stance and their associated parameters. The quantified features of a hemiplegic pair of affected and unaffected force plate recordings are intuitively disparate. Logistic regression achieves 100% classification between an affected and unaffected hemiplegic leg pair based on the feature set of the force plate data.",Medicine and Bioinformatics
24,Expert Bayes: Automatically refining manually built Bayesian networks,"medical informatics, Bayesian networks, structure learning","Bayesian network structures are usually built using only the data and starting from an empty network or from a naive Bayes structure. Very often, in some domains, like medicine, a prior structure is already known based on expert knowledge. This structure can be automatically or manually refined in search for better performance models. In this work, we take Bayesian networks built by specialists and show that minor perturbations to this original network can yield better classifiers with a very small computational cost, while maintaining most of the interpretability of the original network.",Medicine and Bioinformatics
25,Time Warping Symbolic Aggregation Approximation with Bag-of-Patterns Representation for Time Series Classification,"Time series analysis, Correlation, Standards, Error analysis, Vectors, Electrocardiography, Training","Standard Symbolic Aggregation approXimation (SAX) is at the core of many effective time series data mining algorithms. Its combination with Bag-of-Patterns has become the standard approach with bleeding-edge performance on standard datasets. However, standard SAX with BoP representation might neglect the internal temporal correlation embedded in the data. In this paper, we proposed time warping SAX, which extends the standard SAX methods with time delay embedding vector approaches by considering the temporal correlations. We test time warping SAX with BoP representation on 12 benchmark dataset from UCR Time Series Classification/Clustering Page and on 9 of them time warping SAX overtakes the state-of-th-eart performance of standard SAX. To validate our methods in real world applications, a new dataset of vital signs collected from the patients who may require blood transfusion (pRBC) in the next 6 hours are tested. All the results demonstrate that by considering the temporal internal correlation, our time warping SAX with BoP representations could significantly enhance the representation power.",Medicine and Bioinformatics
26,A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies,"Sociology, Statistics, Noise, Testing, Prediction algorithms, Algorithm design and analysis, Genetics","Advances in high frequency trading in financial markets have exceeded the ability of regulators to monitor market stability, creating the need for tools that go beyond market microstructure theory and examine markets in real time, driven by algorithms, as employed in practice. This paper investigates the design, performance and stability of high frequency trading rules using a hybrid evolutionary algorithm based on genetic programming, with a particle swarm optimisation layered on top to improve the genetic operators performance. Our algorithm learns the relevant trading signal information using Foreign Exchange market data. We significantly reduce its execution time by implementing computationally intensive tasks using the Field Programmable Gate Array technology. This approach is shown to provide a reliable platform for examining the stability and nature of optimal trading strategies under different market conditions. We generate robust and significant statistical results on the optimal rules performance and their economic value.",Real-time Systems and Industry
27,Sequential Logistic Principal Component Analysis (SLPCA): Dimensional Reduction in Streaming Multivariate Binary-State System,"energy end-use model, dimensional reduction, sequential optimization","Sequential or online dimensional reduction is of interests due to the explosion of streaming data based applications and the requirement of adaptive statistical modeling, in many emerging fields, such as the modeling of energy end-use profile. Principal Component Analysis (PCA), is the classical way of dimensional reduction. However, traditional Singular Value Decomposition (SVD) based PCA fails to model data which largely deviates from Gaussian distribution. The Bregman Divergence was recently introduced to achieve a generalized PCA framework. If the random variables under dimensional reduction follow Bernoulli distribution, which occurs in many emerging fields, the generalized PCA is called Logistic PCA (LPCA). In this paper, we extend the batch LPCA to a sequential version (i.e. SLPCA), based on the sequential convex optimization theory. The convergence property of this algorithm is discussed compared to the batch version of LPCA (i.e. BLPCA), as well as its performance in reducing the dimension for multivariate binary-state systems. Its application in building energy end-use profile modeling is also investigated.",Real-time Systems and Industry
28,Using k-Nearest Neighbor and Speaker Ranking for Phoneme Prediction,"speech recognition, phoneme, k-Nearest Neighbor, classification, phoneme prediction, template matching","Speech recognition systems are either based on parametric approach or non-parametric approach. Parametric based system such as HMMs have been the dominant technology for speech recognition in the past decade. Despite a lot of advancements and enhancements in the design of these systems:  key problems such as long term temporal dependence, etc. has not yet been solved. Recently due to availability of large amount of data and inexpensive computing resources (processing power and memory) parametric based approach to solve speech recognition and classification task is becoming popular and feasible. The key advantage of parametric based approach is that all the information from the training data is retained as we dont approximate our data with specific statistical models resulting in more speaker specific information. In this paper we propose a kNN phoneme prediction scheme using speaker ranking vector. Speaker ranking vector is generated by finding the similarity of the given TEST speaker with the training data using kNN. The results were compared with nearest neighbor and kNN majority voting approach. Our proposed scheme gives a better prediction accuracy as compare with nearest neighbor and kNN majority voting scheme. This approach can help speech recognizer to customize on the fly for a given talker and customize training data on the basis of similarity measure.",Real-time Systems and Industry
29,A Machine Learning Approach to Combining Individual Strength and Team Features for Team Recommendation,"History, Feature extraction, Outsourcing, Companies, Collaboration, Approximation algorithms","In IT strategic outsourcing businesses, it is critical to have competent deal teams design competitive service solutions and swiftly respond to clients request for proposals. In this paper we present a general team recommendation framework for finding best deal teams to pursue such engagement opportunities. Little previous work on team recommendation considers both individual and team-level features at the same time.  Our proposed framework can take into account diverse individual and team features, and accommodate various cost or feature functions. We introduce a team quality metric based on a weighted linear combination of these features, the weights of which are learned using a machine learning approach by leveraging historical project outcomes. A combinatorial optimization algorithm is finally applied to search the possible solution space for the approximate best team. We report a preliminary evaluation of our framework by applying it to a real-world data from strategic outsourcing businesses at a large IT service company. We also compare our approach with other existing work by using the public DBLP dataset for recommending teams in academic paper authoring.",Real-time Systems and Industry
30,Genetically Supervised Self-Organizing Map for the Classification of Glass Samples,"classification, self-organizing map, genetic optimization and supervision","The self-organizing map (SOM) is a useful tool for creating abstractions of high-dimensional distributions of inputs. It computes the ideal mapping of the domain of observations, using either discrete or continuous distributions of values (1). The SOM benefits from the coupling with a genetic algorithm (GA). GAs are optimization algorithms that allow the user to evolve a solution from a distribution of potential solutions (2). The fittest candidates survive and participate in the production of future generations of new solutions. The fusion of these two techniques results in a dynamic algorithm that maps a diverse input plane in an optimizing fashion, striving towards perfection while learning from mistakes. We will detail the general principles involved and demonstrate the performance of this algorithm in the classification of glass samples.",Real-time Systems and Industry
31,Modelling Mutual Information Between Voiceprint and Optimal Number of Mel-frequency Cepstral Coefficients in Voice Discrimination,"features selection, voiceprint, MFCCs, information theory","In this paper, we study the relationship between the voiceprint and the optimal number of Mel-frequency Cepstral Coefficients (MFCCs) which yields the highest classification accuracy of the voice discrimination. The voiceprint is modelled as sub-MFCCs matrix with the first d number of MFCCs. We model the relationship through information theory and formulate it as the mutual information maximization problem subject to the probabilities constraint. The solution of this optimization problem provides the optimal number of MFCCs, which yields the highest classification accuracy of the voice discrimination, together with a confidence level. This study is dictated by the need to understand the use of MFCCs, which have proliferated since its invention to discriminate voice. We evaluate our model by comparing the leave-one-out cross validation (LOOCV) results of usual multi-class classifier, the Supervised Learning Gaussian Mixture Model (SLGMM), with a set of spoken words and solo acapella singings. The experimental results show that our model is a more comprehensive feature selection criteria for the MFCCs than the de-facto technique, LOOCV.",Information Retrieval I
32,LSH vs Randomized Partition Trees: Which One to Use for Nearest Neighbor Search?,"Nearest neighbor search, RP trees","Recently, randomized partition trees have been theoretically shown (cite{dasgupta13}) to be very effective in performing high dimensional nearest neighbor search. In this paper, we introduce a variant of randomized partition trees  for high dimensional nearest neighbor search problem and provide theoretical justification for its choice. Experiments on various real-life datasets show that this new variant performs better than the variant introduced in cite{dasgupta13}  and also than the locality sensitive hashing (LSH) method for nearest neighbor search. In addition, we show an interesting connection between various  notions of difficulty in nearest neighbor search problem, that have recently been introduced, namely, potential function (cite{dasgupta13}) and relative contrast (cite{he12}).",Information Retrieval I
33,Topic Detection in Instant Messages,"Topic detection, Instant message, PLSA, Multilingual, Useless words","In the past few years, instant messaging (IM) has been widely used in daily communication. However, due to the dispersion of topics and meaningless chatting, online IM groups are filled with useless messages. In order to help IM users capture what the IM group is talking about without spending a long time in reading all the messages, topic discovery in instant messages becomes a significant but challenging research task. In this paper, we propose a new method for topic detection in instant messages, which is applicable for the case where 1) useless terms keep emerging, 2) the instant messages are very short, and 3) multiple languages are used. The basic step is to treat each message in an online group discussion as a data item in message stream, and then apply PLSA to the collected instant messages. One strategy is designed to segment multilingual message without utilizing machine translation and remove the useless words that keep emerging. Extensive experiments have been conducted on the real-world QQ group data to confirm the effectiveness of the proposed method.",Information Retrieval I
34,Automated scoring of the Level of Integrative Complexity from Text using Machine Learning,"integrative complexity, aggression, intervention systems, machine learning, logistic regression, support vector machines","Conceptual/Integrative complexity is a construct developed in political psychology and clinical psychology to measure an individuals ability to consider different perspectives on a particular issue and reach a justifiable conclusion after consideration of said perspectives. Integrative complexity (IC) is usually determined from text through manual scoring, which is time-consuming, laborious and expensive. Consequently, there is a demand for automating the scoring, which could significantly reduce the time, expense and cognitive resources spent in the process. Any algorithm that could achieve the above with a reasonable accuracy could assist in the development of intervention systems for reducing the potential for aggression, systems for recruitment processes and even training personnel for improving group disparity in the corporate world. In this study we used machine learning to predict IC levels from text. We achieved over 78% accuracy in a three way classification.",Information Retrieval I
35,Extraction of Unexpected Rules from Twitter Hashtags and its Application to Sport Events,"Twitter, Association rules, Games, Fans, Pattern matching, Educational institutions","Online news is now widely embraced because of its affordability, rich contents and fast broadcast of diverse real life events and occurrences. Twitter has become a dependable microblogging tool for real time information dissemination and newsworthy events broadcast. Its users sometimes break news on the network faster than traditional newsagents due to their presence at on-going real life events at all times. Different topic detection methods are currently used to match Twitter posts to real life news of mainstream media. In this paper, we analyse events highlights in the English FA Cup final 2012 played between Chelsea FC and Liverpool FC using our novel methodology named TRCM. Our system was able to detect all goals scored in the game, 1 of the 3 bookings and 3 of the four substitutions. Our system also detected other events like free kicks, goal saves and misses  as well as ball clearances and off-side positions that occurred during the match duration. We used the BBC Live Text Commentary as our ground truth to validate our method. The result of the experiment shows that our method performed well as a Topic Detection and Tracking approach.",Information Retrieval II
36,Using Spectral Features to Improve Sentiment Analysis,"feature discovery, spectral learning, discrete Fourier, sentiment analysis","A common approach to sentiment classification is to identify a set of sentiment-carrying words and then to use machine learning to build a classifier that can classify sentiment based on the presence/absence of those words. In this paper, we propose a Fourier-based extension of this approach. Specifically, we introduce a spectral learning algorithm  that implicitly identifies sentiment-carrying words and higher-order functions of those words as it learns to assign real-valued sentiment scores to documents. The spectral learner extends the word presence model by applying Boolean logic operators (AND, OR, and XOR) to the word presence features to identify useful higher-order features. These spectral features can be used in other learning algorithms, and we show how the performance of other learning algorithms can be improved by these features. Finally, we consider the problem of determining which of a pair of reviews expresses more positive overall sentiment, and we show that the spectral learner can identify very small distinctions in sentiment with better-than-random accuracy, while larger distinctions can be correctly identified with high accuracy.",Information Retrieval II
37,Recommendation Systems for Markets with Two Sided Preferences,"Recommender systems, Two-sided markets","In recent times we have witnessed the emergence of large online markets with two-sided preferences that are responsible for businesses worth billions of dollars. Recommendation systems are critical components of such markets. It is to be noted that the matching in such a market depends on the preferences of both sides, consequently, the construction of a recommendation system for such a market calls for consideration of preferences of both sides. The online dating market, and the online freelancer market are examples of markets with two-sided preferences. Past studies on building recommendation systems for such markets, however, lacks a systematic approach. We observe that constructing recommendation systems for markets with two-sided preferences can be posed as an Area Under the receiver operator Curve(AUC) optimization problem. Generalized linear regression models are popular methods of constructing ranking or recommendation systems in such markets on account of their ability to be learned easily from big data, and their computational simplicity on engineering platforms. We conjecture that it is more likely for matching in such markets to be a complex combination of preferences of both sides. To account for this, we introduce a novel two-level model for optimizing the AUC of matching in such markets. For both synthetic and real data we show that the two-level model algorithm has a better AUC performance than the direct application of a generalized linear model such as $L_{1}$ logistic regression or an ensemble method such as random forest algorithm. We provide a theoretical justification of AUC optimality of two-level model and pose a theoretical problem for a more general result. To the best of our knowledge, this is the first systematic study of recommendation systems using AUC optimization in markets with two-sided preferences.",Information Retrieval II
38,Improving Robustness of Gaussian Process-based Inferential Control System using Kernel Principle Component Analysis,"Control systems, Process control, Kernel, Gaussian processes, Principal component analysis, Robustness, Vectors","The plausibility and robustness of an inferential control system entirely depend on the prediction accuracy of the estimator used as the feedback element. This paper is based on a previously proposed Gaussian process inferential controller that employs Gaussian process soft sensor as an estimator. The paper enhances the robustness and the reliability of the control system, particularly, during sensor input failures. The contribution of the paper is i) alleviating the affect of the failure on the prediction accuracy of feedback element (soft sensor) and thus improving the robustness of the overall control system. ii) Hybridising Kernel Principal Component Analysis with Gaussian process Inferential Control System to achieve this robustness during all process operating conditions. The paper empirically shows the effectiveness and the plausibility of the processed hybrid system on a simulated chemical reactor process.",Science and Industry
39,Arctic Sea Ice Extent Forecasting Using Support Vector Regression,"Arctic Sea Ice, SVR, Time Series Forecasting","The summer minimum Arctic sea ice extent has long been used as a measure of climate change, with record lows being reported in recent years. Understanding the dynamics of Arctic sea ice extent is of utmost importance in understanding the timescales associated with this change. Complex global climate models are typically employed to gain insights about the future of Arctic sea ice, however, these models are typically very computationally expensive to solve and the results are often controversial. Here, we use historical data from remote sensing satellites along with machine learning algorithms in the forecasting of Arctic sea ice extent. Support Vector Regression is employed in the learning of a dynamic model to represent this system. Validation results demonstrate the ability of the method to successfully forecast both the seasonal and long-term trends in Arctic sea ice coverage.",Science and Industry
40,WiFi Localization For Mobile Robots based on Random Forests and GPLVM,"WiFi SLAM, Mobile Robots, Random Forests ,GPLVM, Khepera","The proliferation of WiFi networks has attracted many research communities to employ WiFi signals in estimating the location of mobile devices in indoor environments.In this paper, we propose a localization framework that is capable of determining the location of mobile robots in indoor limited areas. The proposed framework exploits the Random Forests algorithm in both classification and regression techniques, which are used to build cooperated supervised localization models. The localization models are trained offline based on training data that contains  measurements of WiFi signal strengths and the location of these measurements. We also proposed an extension to our framework using the Gaussian Process Latent Variable Model (GPLVM), which gives our framework the ability to build subjective localization models which don't require any prior knowledge about ground truth of the localization place. Our experimental evaluation of the proposed framework using KheperaIII mobile robot in one testbed show that it gives high accuracy, where the calculated mean localization error is 36 cm.",Science and Industry
41,Example-Dependent Cost-Sensitive Logistic Regression for Credit Scoring,"Cost sensitive classification, Credit Scoring, Logistic Regression","Several real-world classification problems are example-dependent cost-sensitive in nature, where the costs due to misclassification vary between examples. Credit scoring is a typical example of cost-sensitive classification. However, it is usually treated using methods that do not take into account the real financial costs associated with the lending business. In this paper, we propose a new example-dependent cost matrix for credit scoring. Furthermore, we propose an algorithm that introduces the example-dependent costs into a logistic regression. Using two publicly available datasets, we compare our proposed method against state-of-the-art example-dependent cost-sensitive algorithms. The results highlight the importance of using real financial costs. Moreover, by using the proposed cost-sensitive logistic regression, significant improvements are made in the sense of higher savings.",Science and Industry
42,A Switch-and-Restart Algorithm with Exponential Restart Strategy for Objective Selection and its Runtime Analysis,"runtime analysis, objective selection, algorithm selection, online selection, ea+rl","There exist optimization problems with the target objective, which is to be optimized, and several extra objectives, which may or may not be helpful in the optimization process. This paper considers the case when it is possible to find an optimum of the target objective by optimizing either the target objective or a single extra objective. An algorithm is presented that uses a single instance of an underlying single-objective optimization algorithm to optimize different objectives at different iterations and restarts the optimization algorithm between optimizing different objectives. This algorithm has the expected running time of at most 4 K min_O T_O until an optimum of the target objective is found, where T_O is the expected running time of the underlying optimization algorithm to find an optimum of the target objective by optimizing the objective O. An impact of not using restarts between iterations is also discussed.",Machine Learning II
43,Adding Diversity to Rank Examples in Anytime Nearest Neighbor Classification,"Anytime Algorithm, Nearest Neighbor, Classification, Data Stream","Data streams are ubiquitous in virtually every application domain. However, a property that is common to various domains and is frequently disregarded is the very high fluctuating data rates, in which the events do not occur with a fixed frequency. The classical learning algorithms do not seem to be adequate in such a scenario. In contrast, anytime classification provides a very convenient approach for this situation. In summary, an anytime classifier can be interrupted at any time before its completion and still be able to provide an intermediate classification. The popular k-nearest neighbor classifier can be easily made anytime by introducing a ranking of the training examples. In this paper, we show how the current state-of-the-art k-NN anytime classifier can be made more accurate by introducing diversity in the training set ranking. Our results show that, with this simple modification, the performance of the anytime version of the k-NN algorithm is consistently improved for a large number of datasets.",Machine Learning II
44,Improved kNN Rule for Small Training Sets,"Error analysis, Training, Prediction algorithms, Data models, Computer science, Educational institutions, Electronic mail","The traditional k-NN classification rule predicts a label based on the most common label of the k nearest neighbors (the plurality rule). It is known that the plurality rule is optimal when the number of examples tends to infinity. In this paper we show that the plurality rule is sub-optimal when the number of labels is large and the number of examples is small. We propose a simple k-NN rule that takes into account the labels of all of the neighbors, rather than just the most common label. We present a number of experiments on both synthetic datasets and real-world datasets, including MNIST and SVHN. We show that our new rule can achieve lower error rates compared to the majority rule in many cases.",Machine Learning II
45,Computation of a Rejection Threshold used for the Bayes Classifier,"rejection, statistical learning, bayes classifier",In this paper an algorithm for the efficient computation of a rejection threshold for Bayes classification is discussed. A theoretical and a practical evaluation of the performance regarding the accuracy of the numerical computation for uni- and multimodal high-dimensional probability distributions is given. Additionally some observations regarding the dimensionality and the number of samples are shared.,Machine Learning II
46,Protein Conformation Motion Modeling using sep-CMA-ES,"mass transfer, cma-es, protein conformation, conformation motion","The problem of protein conformation motion modeling is an open problem in the structural computational biology. It is difficult to solve it using methods of molecular dynamics or quantum physics because these methods deal with time intervals of nanoseconds or microseconds, while conformation motions take time of millisecond order. In addition, these methods cannot take external forces into consideration. To cope with these problems, numerous approximated and coarse-grained methods are developed, which use ideas from geometry and motion planning.We present a new coarse-grained method of modeling the protein motion between two given conformations. The method is based on optimization of a cost function similar to the one in the Monge-Kantorovich mass transfer problem. The optimization is performed using sep-CMA-ES, which makes the running time of an iteration linear in the number of amino acids in a protein. The proposed method is compared with some of the existing methods on several molecules. It is shown that the results of the proposed method are more accurate than of the other methods.","Medicine, Science and Music"
47,Budgeted Learning for Developing Personalized Treatment,"Reinforcement Learning, Budgeted Learning, Bayesian, Active Learning, Personalized Treatment","There is increased interest in using patient-specific information to  personalize treatment. Personalized treatment decision rules can be learned using data from standard clinical trials, but such trials are very costly to run. This paper explores the use of budgeted learning techniques to design more efficient clinical trials, by effectively determining which type of patients to recruit, at each time, throughout the duration of the trial. We propose a Bayesian bandit model and discuss the computational challenges and issues pertaining to this approach. We compare our budgeted learning algorithm, which approximately minimizes the Bayes risk, using both simulated data and data modeled after a clinical trial for treating depressed individuals, with other plausible algorithms. We show that our budgeted learning algorithm demonstrated excellent performance across a wide variety of situations.","Medicine, Science and Music"
48,Visualising Singing Style Under Common Musical Events Using Pitch-Dynamics Trajectories and Modified TRACLUS Clustering,"TRACLUS Clustering, Visualising, Singing Style, Music Event","In this paper, we present a novel method for visualising the singing style of vocalists. To illustrate our method, we take 26 audio recordings of a capella solo vocal music from two different professional singers and we visualise the performance style of each vocalist in a two dimensional space of pitch and dynamics. We use our own novel modification of a trajectory clustering algorithm called TRACLUS to generate four representative paths, called trajectories, in that two dimensional space.  Each trajectory represents the characteristic style of a vocalist during one of four common musical events: (1) Crescendo, (2) Diminuendo, (3) Ascending Pitches and (4) Descending Pitches. The unique shapes of these trajectories characterize the singing style of each vocalist with respect to each of these events. We present the details of our modified version of the TRACULUS algorithm and demonstrate graphically how the plots produced indicate distinct stylistic differences betweens singers. Potential applications for this method include: (a) automatic identification of singers and automatic classification of singing styles and (b) automatic retargeting of performance style to add human expression to computer generated vocal performances and allow singing synthesisers to imitate the styles of specific famous professional vocalists.","Medicine, Science and Music"
49,Supervised Music Chord Recognition,"Music, chord, feature","Chord represents the back-bone of occidental music genre as it contains rich harmonic information which is useful for various music applications such as music genre classification or music retrieval. Hence, chord recognition or transcription is of importance for music representation. In this paper we focus on chord recognition and especially investigate different features representation used in such a system:  classical features as well as a new type of feature we propose are explored.  We evaluate their usefulness through a multi-class chord classification problem.","Medicine, Science and Music"
50,Uncertainty Quantified Matrix Completion using Bayesian Hierarchical Matrix Factorization,"Bayesian Analysis, Probabilistic Matrix Factorization, Uncertainty Quantification","Low-rank matrix completion methods have been successful in a variety of settings such as recommendation systems. However, most of the existing matrix completion methods only provide a point estimate of missing entries, and do not characterize uncertainties of the predictions. In this paper, we propose a Bayesian hierarchical probabilistic matrix factorization (BHPMF) model to 1) incorporate hierarchical side information, and 2) provide uncertainty quantified predictions. The former yields significant performance improvements in the problem of plant trait prediction, a key problem in ecology, by leveraging the taxonomic hierarchy in the plant kingdom. The latter is helpful in identifying predictions of low confidence which can in turn be used to guide field work for data collection efforts. A Gibbs sampler is designed for inference in the model. Further, we propose a multiple inheritance BHPMF (MI-BHPMF) which can work with a general directed acyclic graph (DAG) structured hierarchy, rather than a tree. We present comprehensive experimental results on the problem of plant trait prediction using the largest database of plant traits, where BHPMF shows strong empirical performance in uncertainty quantified trait prediction, outperforming the state-of-the-art based on point estimates. Further, we show that BHPMF is more accurate when it is confident, whereas the error is high when the uncertainty is high.","Medicine, Science and Music"
